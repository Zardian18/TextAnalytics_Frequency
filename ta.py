# -*- coding: utf-8 -*-
"""TA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OupnR5P7O1ZUYV-9_rh_78hFfOHiyZ3d
"""

import pandas as pd
import numpy as np
import re
import json
from collections import Counter
from scipy import stats
from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu
from scipy.stats.mstats import kruskalwallis
from scipy.stats import linregress
from nltk.corpus import stopwords
import nltk

# Download NLTK stopwords if not already present
nltk.download('stopwords', quiet=True)

def load_corpus(csv_file_path):
    """Load the preprocessed corpus from a CSV file."""
    try:
        df = pd.read_csv(csv_file_path)
        print(f"Successfully loaded CSV file with {len(df)} rows.")
        return df
    except Exception as e:
        print(f"Error loading CSV file: {e}")
        return pd.DataFrame()

def categorize_stopwords(word):
    """Categorize stop words into different types."""
    determiners = {'the', 'a', 'an', 'this', 'that', 'these', 'those', 'my', 'your', 'his', 'her', 'its', 'our', 'their'}
    prepositions = {'in', 'on', 'at', 'by', 'for', 'with', 'about', 'as', 'into', 'like', 'of', 'off', 'to', 'from', 'up', 'down'}
    negations = {'no', 'not', 'none', 'nor', 'never', 'neither'}

    if word in determiners:
        return 'determiner'
    elif word in prepositions:
        return 'preposition'
    elif word in negations:
        return 'negation'
    else:
        return 'adverbial/other'

def analyze_stopwords(df):
    """Analyze stop words in each utterance and categorize them."""
    english_stopwords = set(stopwords.words('english'))

    results = []

    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))

        # Tokenize the utterance into individual words
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        total_words = len(tokens)

        if total_words == 0:  # Skip empty utterances
            continue

        # Count stop words by category
        stop_counts = {
            'determiner': 0,
            'preposition': 0,
            'negation': 0,
            'adverbial/other': 0,
            'total_stopwords': 0
        }

        for token in tokens:
            if token in english_stopwords:
                category = categorize_stopwords(token)
                stop_counts[category] += 1
                stop_counts['total_stopwords'] += 1

        # Build result with metadata and frequency calculations
        result = {
            'speaker_id': str(row.get('speaker_id', '')),
            'gender': str(row.get('gender', '')).lower(),
            'native_language': str(row.get('native_language', '')),
            'age': str(row.get('age', '')),
            'discipline': str(row.get('discipline', '')),
            'native_language': 1 if str(row.get('native_language', '')).lower() == 'english' else 0,
            'total_words': total_words
        }

        # Calculate frequencies for each category
        for category, count in stop_counts.items():
            result[f'{category}_count'] = count
            result[f'{category}_freq'] = count / total_words if total_words > 0 else 0
            result[f'{category}_disc_freq'] = np.sqrt(count) / total_words if total_words > 0 else 0

        results.append(result)

    return pd.DataFrame(results)

def parametric_tests(df):
    """Perform parametric tests (t-tests) for gender, age, and discipline."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform t-test
                t_stat, p_val = ttest_ind(male_data, female_data, equal_var=False)
                gender_results[category] = {
                    't_stat': float(t_stat),
                    'p_value': float(p_val),
                    'male_mean': float(male_data.mean()),
                    'female_mean': float(female_data.mean()),
                    'male_std': float(male_data.std()),
                    'female_std': float(female_data.std()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using ANOVA for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = stats.f_oneway(*group_data)

                    # Also calculate pairwise t-tests between age groups
                    pairwise = {}
                    for i, age1 in enumerate(age_groups):
                        for j, age2 in enumerate(age_groups):
                            if i < j and age1 in df['age'].values and age2 in df['age'].values:
                                data1 = df[df['age'] == age1][freq_col].dropna()
                                data2 = df[df['age'] == age2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{age1}_vs_{age2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    age_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {age: float(df[df['age'] == age][freq_col].mean()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using ANOVA for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = stats.f_oneway(*group_data)

                    # Also calculate pairwise t-tests between disciplines
                    pairwise = {}
                    for i, disc1 in enumerate(disciplines):
                        for j, disc2 in enumerate(disciplines):
                            if i < j and disc1 in df['discipline'].values and disc2 in df['discipline'].values:
                                data1 = df[df['discipline'] == disc1][freq_col].dropna()
                                data2 = df[df['discipline'] == disc2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{disc1}_vs_{disc2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    discipline_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {disc: float(df[df['discipline'] == disc][freq_col].mean()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    return results

def nonparametric_tests(df):
    """Perform non-parametric tests (Mann-Whitney U and Kruskal-Wallis) for gender, age, and discipline."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform Mann-Whitney U test
                u_stat, p_val = mannwhitneyu(male_data, female_data, alternative='two-sided')
                gender_results[category] = {
                    'u_stat': float(u_stat),
                    'p_value': float(p_val),
                    'male_median': float(male_data.median()),
                    'female_median': float(female_data.median()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using Kruskal-Wallis for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    age_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {age: float(df[df['age'] == age][freq_col].median()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using Kruskal-Wallis for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    discipline_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {disc: float(df[df['discipline'] == disc][freq_col].median()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    return results

def chi_square_analysis(df):
    """Perform chi-square tests for gender, age, and discipline."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['gender'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    gender_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                gender_results[category] = {'error': str(e)}

    results['gender'] = gender_results

    # Age group comparisons
    age_results = {}
    if 'age' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['age'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    age_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                age_results[category] = {'error': str(e)}

    results['age'] = age_results

    # Discipline comparisons
    discipline_results = {}
    if 'discipline' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['discipline'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    discipline_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                discipline_results[category] = {'error': str(e)}

    results['discipline'] = discipline_results

    return results

def analyze_zipf_law(df):
    """Analyze Zipf's Law for stop words across different groups."""
    english_stopwords = set(stopwords.words('english'))
    results = {}

    # Overall analysis
    all_stop_words = []
    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        all_stop_words.extend([token for token in tokens if token in english_stopwords])

    if all_stop_words:
        results['overall'] = calculate_zipf(all_stop_words)

    # By gender
    gender_results = {}
    if 'gender' in df.columns:
        for gender in df['gender'].unique():
            gender_utterances = df[df['gender'] == gender]['utterance']
            stop_words = []
            for utterance in gender_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                gender_results[gender] = calculate_zipf(stop_words)
    results['gender'] = gender_results

    # By age group
    age_results = {}
    if 'age' in df.columns:
        for age in df['age'].unique():
            age_utterances = df[df['age'] == age]['utterance']
            stop_words = []
            for utterance in age_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                age_results[age] = calculate_zipf(stop_words)
    results['age'] = age_results

    # By discipline
    discipline_results = {}
    if 'discipline' in df.columns:
        for discipline in df['discipline'].unique():
            disc_utterances = df[df['discipline'] == discipline]['utterance']
            stop_words = []
            for utterance in disc_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                discipline_results[discipline] = calculate_zipf(stop_words)
    results['discipline'] = discipline_results

    return results

def calculate_zipf(word_list):
    """Calculate Zipf's Law parameters for a list of words."""
    if not word_list:
        return {'error': 'Empty word list'}

    word_counts = Counter(word_list)
    word_freqs = [(word, count) for word, count in word_counts.items()]
    word_freqs.sort(key=lambda x: x[1], reverse=True)

    ranks = np.arange(1, len(word_freqs) + 1)
    frequencies = np.array([freq for _, freq in word_freqs])

    # Calculate the Zipf coefficient
    slope, intercept, r_value, p_value, std_err = linregress(
        np.log(ranks), np.log(frequencies))

    return {
        'zipf_coefficient': -float(slope),  # Negative as Zipf's law has a negative slope
        'r_squared': float(r_value**2),
        'p_value': float(p_value),
        'std_error': float(std_err),
        'intercept': float(intercept),
        'top_words': word_freqs[:10]  # Include top 10 words for inspection
    }

def save_results(results, filename):
    """Save results to a JSON file."""
    # Convert numpy types to Python native types
    def convert(o):
        if isinstance(o, np.integer):
            return int(o)
        elif isinstance(o, np.floating):
            return float(o)
        elif isinstance(o, np.ndarray):
            return o.tolist()
        else:
            return o

    with open(filename, 'w') as f:
        json.dump(results, f, default=convert, indent=2)

def main():
    # Step 1: Load the preprocessed CSV file
    csv_file_path = '/content/elfa_processed.csv'  # Update this path
    print(f"Loading CSV file from: {csv_file_path}")
    df = load_corpus(csv_file_path)

    if df.empty:
        print("Error: No data was loaded. Check your CSV file path.")
        return

    print(f"Loaded {len(df)} records with columns: {list(df.columns)}")

    # Step 2: Analyze stop words
    print("Analyzing stop words...")
    stopword_df = analyze_stopwords(df)

    if stopword_df.empty:
        print("Error: No stop word data was generated.")
        return

    print(f"Generated stopword analysis with {len(stopword_df)} records")

    # Step 3: Perform statistical analyses
    print("Running parametric tests...")
    parametric_results = parametric_tests(stopword_df)
    save_results(parametric_results, 'parametric_results.json')
    print("Saved parametric results to parametric_results.json")

    print("Running non-parametric tests...")
    nonparametric_results = nonparametric_tests(stopword_df)
    save_results(nonparametric_results, 'nonparametric_results.json')
    print("Saved non-parametric results to nonparametric_results.json")

    print("Running chi-square tests...")
    chi_square_results = chi_square_analysis(stopword_df)
    save_results(chi_square_results, 'chi_square_results.json')
    print("Saved chi-square results to chi_square_results.json")

    print("Running Zipf's Law analysis...")
    zipf_results = analyze_zipf_law(df)
    save_results(zipf_results, 'zipf_results.json')
    print("Saved Zipf's Law results to zipf_results.json")

    print("\nAll analyses completed successfully!")

if __name__ == '__main__':
    main()

import pandas as pd
import numpy as np
import re
import json
from collections import Counter
from scipy import stats
from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu
from scipy.stats.mstats import kruskalwallis
from scipy.stats import linregress
from nltk.corpus import stopwords
import nltk

# Download NLTK stopwords if not already present
nltk.download('stopwords', quiet=True)

def load_corpus(csv_file_path):
    """Load the preprocessed corpus from a CSV file."""
    try:
        df = pd.read_csv(csv_file_path)
        print(f"Successfully loaded CSV file with {len(df)} rows.")
        return df
    except Exception as e:
        print(f"Error loading CSV file: {e}")
        return pd.DataFrame()

def categorize_stopwords(word):
    """Categorize stop words into different types."""
    determiners = {'the', 'a', 'an', 'this', 'that', 'these', 'those', 'my', 'your', 'his', 'her', 'its', 'our', 'their'}
    prepositions = {'in', 'on', 'at', 'by', 'for', 'with', 'about', 'as', 'into', 'like', 'of', 'off', 'to', 'from', 'up', 'down'}
    negations = {'no', 'not', 'none', 'nor', 'never', 'neither'}

    if word in determiners:
        return 'determiner'
    elif word in prepositions:
        return 'preposition'
    elif word in negations:
        return 'negation'
    else:
        return 'adverbial/other'

def analyze_stopwords(df):
    """Analyze stop words in each utterance and categorize them."""
    english_stopwords = set(stopwords.words('english'))

    results = []

    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))

        # Tokenize the utterance into individual words
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        total_words = len(tokens)

        if total_words == 0:  # Skip empty utterances
            continue

        # Count stop words by category
        stop_counts = {
            'determiner': 0,
            'preposition': 0,
            'negation': 0,
            'adverbial/other': 0,
            'total_stopwords': 0
        }

        for token in tokens:
            if token in english_stopwords:
                category = categorize_stopwords(token)
                stop_counts[category] += 1
                stop_counts['total_stopwords'] += 1

        # Build result with metadata and frequency calculations
        result = {
            'speaker_id': str(row.get('speaker_id', '')),
            'gender': str(row.get('gender', '')).lower(),
            'native_language': str(row.get('native_language', '')),
            'age': str(row.get('age', '')),
            'discipline': str(row.get('discipline', '')),
            'native_language': 1 if str(row.get('native_language', '')).lower() == 'english' else 0,
            'total_words': total_words
        }

        # Calculate frequencies for each category
        for category, count in stop_counts.items():
            result[f'{category}_count'] = count
            result[f'{category}_freq'] = count / total_words if total_words > 0 else 0
            result[f'{category}_disc_freq'] = np.sqrt(count) / total_words if total_words > 0 else 0

        results.append(result)

    return pd.DataFrame(results)

def parametric_tests(df):
    """Perform parametric tests (t-tests) for gender, age, discipline, and native status."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform t-test
                t_stat, p_val = ttest_ind(male_data, female_data, equal_var=False)
                gender_results[category] = {
                    't_stat': float(t_stat),
                    'p_value': float(p_val),
                    'male_mean': float(male_data.mean()),
                    'female_mean': float(female_data.mean()),
                    'male_std': float(male_data.std()),
                    'female_std': float(female_data.std()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using ANOVA for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = stats.f_oneway(*group_data)

                    # Also calculate pairwise t-tests between age groups
                    pairwise = {}
                    for i, age1 in enumerate(age_groups):
                        for j, age2 in enumerate(age_groups):
                            if i < j and age1 in df['age'].values and age2 in df['age'].values:
                                data1 = df[df['age'] == age1][freq_col].dropna()
                                data2 = df[df['age'] == age2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{age1}_vs_{age2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    age_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {age: float(df[df['age'] == age][freq_col].mean()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using ANOVA for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = stats.f_oneway(*group_data)

                    # Also calculate pairwise t-tests between disciplines
                    pairwise = {}
                    for i, disc1 in enumerate(disciplines):
                        for j, disc2 in enumerate(disciplines):
                            if i < j and disc1 in df['discipline'].values and disc2 in df['discipline'].values:
                                data1 = df[df['discipline'] == disc1][freq_col].dropna()
                                data2 = df[df['discipline'] == disc2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{disc1}_vs_{disc2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    discipline_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {disc: float(df[df['discipline'] == disc][freq_col].mean()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    # Native speaker comparisons
    native_results = {}
    if 'native_language' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by native status
            native_data = df[df['native_language'] == 1][freq_col].dropna()
            non_native_data = df[df['native_language'] == 0][freq_col].dropna()

            if len(native_data) > 1 and len(non_native_data) > 1:
                # Perform t-test
                t_stat, p_val = ttest_ind(native_data, non_native_data, equal_var=False)
                native_results[category] = {
                    't_stat': float(t_stat),
                    'p_value': float(p_val),
                    'native_mean': float(native_data.mean()),
                    'non_native_mean': float(non_native_data.mean()),
                    'native_std': float(native_data.std()),
                    'non_native_std': float(non_native_data.std()),
                    'native_n': len(native_data),
                    'non_native_n': len(non_native_data)
                }

    results['native_speaker'] = native_results

    return results

def nonparametric_tests(df):
    """Perform non-parametric tests (Mann-Whitney U and Kruskal-Wallis) for gender, age, discipline, and native status."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform Mann-Whitney U test
                u_stat, p_val = mannwhitneyu(male_data, female_data, alternative='two-sided')
                gender_results[category] = {
                    'u_stat': float(u_stat),
                    'p_value': float(p_val),
                    'male_median': float(male_data.median()),
                    'female_median': float(female_data.median()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using Kruskal-Wallis for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    age_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {age: float(df[df['age'] == age][freq_col].median()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using Kruskal-Wallis for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    discipline_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {disc: float(df[df['discipline'] == disc][freq_col].median()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    # Native speaker comparisons
    native_results = {}
    if 'native_language' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by native status
            native_data = df[df['native_language'] == 1][freq_col].dropna()
            non_native_data = df[df['native_language'] == 0][freq_col].dropna()

            if len(native_data) > 1 and len(non_native_data) > 1:
                # Perform Mann-Whitney U test
                u_stat, p_val = mannwhitneyu(native_data, non_native_data, alternative='two-sided')
                native_results[category] = {
                    'u_stat': float(u_stat),
                    'p_value': float(p_val),
                    'native_median': float(native_data.median()),
                    'non_native_median': float(non_native_data.median()),
                    'native_n': len(native_data),
                    'non_native_n': len(non_native_data)
                }

    results['native_speaker'] = native_results

    return results

def chi_square_analysis(df):
    """Perform chi-square tests for gender, age, discipline, and native status."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['gender'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    gender_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                gender_results[category] = {'error': str(e)}

    results['gender'] = gender_results

    # Age group comparisons
    age_results = {}
    if 'age' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['age'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    age_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                age_results[category] = {'error': str(e)}

    results['age'] = age_results

    # Discipline comparisons
    discipline_results = {}
    if 'discipline' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['discipline'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    discipline_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                discipline_results[category] = {'error': str(e)}

    results['discipline'] = discipline_results

    # Native speaker comparisons
    native_results = {}
    if 'native_language' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['native_language'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    native_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                native_results[category] = {'error': str(e)}

    results['native_language'] = native_results

    return results

def analyze_zipf_law(df):
    """Analyze Zipf's Law for stop words across different groups."""
    english_stopwords = set(stopwords.words('english'))
    results = {}

    # Overall analysis
    all_stop_words = []
    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        all_stop_words.extend([token for token in tokens if token in english_stopwords])

    if all_stop_words:
        results['overall'] = calculate_zipf(all_stop_words)

    # By gender
    gender_results = {}
    if 'gender' in df.columns:
        for gender in df['gender'].unique():
            gender_utterances = df[df['gender'] == gender]['utterance']
            stop_words = []
            for utterance in gender_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                gender_results[gender] = calculate_zipf(stop_words)
    results['gender'] = gender_results

    # By age group
    age_results = {}
    if 'age' in df.columns:
        for age in df['age'].unique():
            age_utterances = df[df['age'] == age]['utterance']
            stop_words = []
            for utterance in age_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                age_results[age] = calculate_zipf(stop_words)
    results['age'] = age_results

    # By discipline
    discipline_results = {}
    if 'discipline' in df.columns:
        for discipline in df['discipline'].unique():
            disc_utterances = df[df['discipline'] == discipline]['utterance']
            stop_words = []
            for utterance in disc_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                discipline_results[discipline] = calculate_zipf(stop_words)
    results['discipline'] = discipline_results

    # By native speaker status
    native_results = {}
    if 'native_language' in df.columns:
        for native_language in df['native_language'].unique():
            native_language_utterances = df[df['native_language'] == native_language]['utterance']
            stop_words = []
            for utterance in native_language_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                native_results[native_language] = calculate_zipf(stop_words)
    results['native_language'] = native_results

    return results

def calculate_zipf(word_list):
    """Calculate Zipf's Law parameters for a list of words."""
    if not word_list:
        return {'error': 'Empty word list'}

    word_counts = Counter(word_list)
    word_freqs = [(word, count) for word, count in word_counts.items()]
    word_freqs.sort(key=lambda x: x[1], reverse=True)

    ranks = np.arange(1, len(word_freqs) + 1)
    frequencies = np.array([freq for _, freq in word_freqs])

    # Calculate the Zipf coefficient
    slope, intercept, r_value, p_value, std_err = linregress(
        np.log(ranks), np.log(frequencies))

    return {
        'zipf_coefficient': -float(slope),  # Negative as Zipf's law has a negative slope
        'r_squared': float(r_value**2),
        'p_value': float(p_value),
        'std_error': float(std_err),
        'intercept': float(intercept),
        'top_words': word_freqs[:10]  # Include top 10 words for inspection
    }

def save_results(results, filename):
    """Save results to a JSON file."""
    # Convert numpy types to Python native types
    def convert(o):
        if isinstance(o, np.integer):
            return int(o)
        elif isinstance(o, np.floating):
            return float(o)
        elif isinstance(o, np.ndarray):
            return o.tolist()
        else:
            return o

    with open(filename, 'w') as f:
        json.dump(results, f, default=convert, indent=2)

def main():
    # Step 1: Load the preprocessed CSV file
    csv_file_path = '/content/elfa_processed.csv'  # Update this path
    print(f"Loading CSV file from: {csv_file_path}")
    df = load_corpus(csv_file_path)

    if df.empty:
        print("Error: No data was loaded. Check your CSV file path.")
        return

    print(f"Loaded {len(df)} records with columns: {list(df.columns)}")

    # Step 2: Analyze stop words
    print("Analyzing stop words...")
    stopword_df = analyze_stopwords(df)

    if stopword_df.empty:
        print("Error: No stop word data was generated.")
        return

    print(f"Generated stopword analysis with {len(stopword_df)} records")

    # Step 3: Perform statistical analyses
    print("Running parametric tests...")
    parametric_results = parametric_tests(stopword_df)
    save_results(parametric_results, 'parametric_results.json')
    print("Saved parametric results to parametric_results.json")

    print("Running non-parametric tests...")
    nonparametric_results = nonparametric_tests(stopword_df)
    save_results(nonparametric_results, 'nonparametric_results.json')
    print("Saved non-parametric results to nonparametric_results.json")

    print("Running chi-square tests...")
    chi_square_results = chi_square_analysis(stopword_df)
    save_results(chi_square_results, 'chi_square_results.json')
    print("Saved chi-square results to chi_square_results.json")

    print("Running Zipf's Law analysis...")
    zipf_results = analyze_zipf_law(df)
    save_results(zipf_results, 'zipf_results.json')
    print("Saved Zipf's Law results to zipf_results.json")

    print("\nAll analyses completed successfully!")

if __name__ == '__main__':
    main()

import pandas as pd
import numpy as np
import re
import json
from collections import Counter
from scipy import stats
from scipy.stats import chi2_contingency, ttest_ind, mannwhitneyu, f_oneway
from scipy.stats.mstats import kruskalwallis
from scipy.stats import linregress
from nltk.corpus import stopwords
import nltk

# Download NLTK stopwords if not already present
nltk.download('stopwords', quiet=True)

def load_corpus(csv_file_path):
    """Load the preprocessed corpus from a CSV file."""
    try:
        df = pd.read_csv(csv_file_path)
        print(f"Successfully loaded CSV file with {len(df)} rows.")
        return df
    except Exception as e:
        print(f"Error loading CSV file: {e}")
        return pd.DataFrame()

def categorize_stopwords(word):
    """Categorize stop words into different types."""
    determiners = {'the', 'a', 'an', 'this', 'that', 'these', 'those', 'my', 'your', 'his', 'her', 'its', 'our', 'their'}
    prepositions = {'in', 'on', 'at', 'by', 'for', 'with', 'about', 'as', 'into', 'like', 'of', 'off', 'to', 'from', 'up', 'down'}
    negations = {'no', 'not', 'none', 'nor', 'never', 'neither'}

    if word in determiners:
        return 'determiner'
    elif word in prepositions:
        return 'preposition'
    elif word in negations:
        return 'negation'
    else:
        return 'adverbial/other'

def analyze_stopwords(df):
    """Analyze stop words in each utterance and categorize them."""
    english_stopwords = set(stopwords.words('english'))

    results = []

    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))

        # Tokenize the utterance into individual words
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        total_words = len(tokens)

        if total_words == 0:  # Skip empty utterances
            continue

        # Count stop words by category
        stop_counts = {
            'determiner': 0,
            'preposition': 0,
            'negation': 0,
            'adverbial/other': 0,
            'total_stopwords': 0
        }

        for token in tokens:
            if token in english_stopwords:
                category = categorize_stopwords(token)
                stop_counts[category] += 1
                stop_counts['total_stopwords'] += 1

        # Build result with metadata and frequency calculations
        result = {
            'speaker_id': str(row.get('speaker_id', '')),
            'gender': str(row.get('gender', '')).lower(),
            'native_language': str(row.get('native_language', '')).lower(),
            'age': str(row.get('age', '')),
            'discipline': str(row.get('discipline', '')),
            'total_words': total_words
        }

        # Calculate frequencies for each category
        for category, count in stop_counts.items():
            result[f'{category}_count'] = count
            result[f'{category}_freq'] = count / total_words if total_words > 0 else 0
            result[f'{category}_disc_freq'] = np.sqrt(count) / total_words if total_words > 0 else 0

        results.append(result)

    return pd.DataFrame(results)

def parametric_tests(df):
    """Perform parametric tests (t-tests and ANOVA) for gender, age, discipline, and native language."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform t-test
                t_stat, p_val = ttest_ind(male_data, female_data, equal_var=False)
                gender_results[category] = {
                    't_stat': float(t_stat),
                    'p_value': float(p_val),
                    'male_mean': float(male_data.mean()),
                    'female_mean': float(female_data.mean()),
                    'male_std': float(male_data.std()),
                    'female_std': float(female_data.std()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using ANOVA for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = f_oneway(*group_data)

                    # Also calculate pairwise t-tests between age groups
                    pairwise = {}
                    for i, age1 in enumerate(age_groups):
                        for j, age2 in enumerate(age_groups):
                            if i < j and age1 in df['age'].values and age2 in df['age'].values:
                                data1 = df[df['age'] == age1][freq_col].dropna()
                                data2 = df[df['age'] == age2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{age1}_vs_{age2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    age_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {age: float(df[df['age'] == age][freq_col].mean()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using ANOVA for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = f_oneway(*group_data)

                    # Also calculate pairwise t-tests between disciplines
                    pairwise = {}
                    for i, disc1 in enumerate(disciplines):
                        for j, disc2 in enumerate(disciplines):
                            if i < j and disc1 in df['discipline'].values and disc2 in df['discipline'].values:
                                data1 = df[df['discipline'] == disc1][freq_col].dropna()
                                data2 = df[df['discipline'] == disc2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{disc1}_vs_{disc2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    discipline_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {disc: float(df[df['discipline'] == disc][freq_col].mean()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    # Native language comparisons (using ANOVA for multiple groups)
    language_results = {}
    if 'native_language' in df.columns:
        languages = [lang for lang in df['native_language'].unique() if pd.notna(lang)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['native_language'] == lang][freq_col].dropna() for lang in languages if len(df[df['native_language'] == lang]) > 1]

            if len(group_data) >= 2:
                # Perform one-way ANOVA
                try:
                    f_stat, p_val = f_oneway(*group_data)

                    # Also calculate pairwise t-tests between languages
                    pairwise = {}
                    for i, lang1 in enumerate(languages):
                        for j, lang2 in enumerate(languages):
                            if i < j and lang1 in df['native_language'].values and lang2 in df['native_language'].values:
                                data1 = df[df['native_language'] == lang1][freq_col].dropna()
                                data2 = df[df['native_language'] == lang2][freq_col].dropna()
                                if len(data1) > 1 and len(data2) > 1:
                                    t_stat, p_val_pair = ttest_ind(data1, data2, equal_var=False)
                                    pairwise[f'{lang1}_vs_{lang2}'] = {
                                        't_stat': float(t_stat),
                                        'p_value': float(p_val_pair),
                                        'mean_diff': float(data1.mean() - data2.mean())
                                    }

                    language_results[category] = {
                        'f_stat': float(f_stat),
                        'p_value': float(p_val),
                        'group_means': {lang: float(df[df['native_language'] == lang][freq_col].mean()) for lang in languages},
                        'group_counts': {lang: len(df[df['native_language'] == lang]) for lang in languages},
                        'pairwise': pairwise
                    }
                except Exception as e:
                    print(f"Error in ANOVA for {category}: {str(e)}")
                    continue

    results['native_language'] = language_results

    return results

def nonparametric_tests(df):
    """Perform non-parametric tests (Mann-Whitney U and Kruskal-Wallis) for gender, age, discipline, and native language."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            # Separate data by gender
            male_data = df[df['gender'] == 'male'][freq_col].dropna()
            female_data = df[df['gender'] == 'female'][freq_col].dropna()

            if len(male_data) > 1 and len(female_data) > 1:
                # Perform Mann-Whitney U test
                u_stat, p_val = mannwhitneyu(male_data, female_data, alternative='two-sided')
                gender_results[category] = {
                    'u_stat': float(u_stat),
                    'p_value': float(p_val),
                    'male_median': float(male_data.median()),
                    'female_median': float(female_data.median()),
                    'male_n': len(male_data),
                    'female_n': len(female_data)
                }

    results['gender'] = gender_results

    # Age group comparisons (using Kruskal-Wallis for multiple groups)
    age_results = {}
    if 'age' in df.columns:
        age_groups = [age for age in df['age'].unique() if pd.notna(age)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['age'] == age][freq_col].dropna() for age in age_groups if len(df[df['age'] == age]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    age_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {age: float(df[df['age'] == age][freq_col].median()) for age in age_groups},
                        'group_counts': {age: len(df[df['age'] == age]) for age in age_groups}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['age'] = age_results

    # Discipline comparisons (using Kruskal-Wallis for multiple groups)
    discipline_results = {}
    if 'discipline' in df.columns:
        disciplines = [disc for disc in df['discipline'].unique() if pd.notna(disc)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['discipline'] == disc][freq_col].dropna() for disc in disciplines if len(df[df['discipline'] == disc]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    discipline_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {disc: float(df[df['discipline'] == disc][freq_col].median()) for disc in disciplines},
                        'group_counts': {disc: len(df[df['discipline'] == disc]) for disc in disciplines}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['discipline'] = discipline_results

    # Native language comparisons (using Kruskal-Wallis for multiple groups)
    language_results = {}
    if 'native_language' in df.columns:
        languages = [lang for lang in df['native_language'].unique() if pd.notna(lang)]

        for category in categories:
            freq_col = f'{category}_freq'
            if freq_col not in df.columns:
                continue

            group_data = [df[df['native_language'] == lang][freq_col].dropna() for lang in languages if len(df[df['native_language'] == lang]) > 1]

            if len(group_data) >= 2:
                # Perform Kruskal-Wallis test
                try:
                    h_stat, p_val = kruskalwallis(*group_data)
                    language_results[category] = {
                        'h_stat': float(h_stat),
                        'p_value': float(p_val),
                        'group_medians': {lang: float(df[df['native_language'] == lang][freq_col].median()) for lang in languages},
                        'group_counts': {lang: len(df[df['native_language'] == lang]) for lang in languages}
                    }
                except Exception as e:
                    print(f"Error in Kruskal-Wallis for {category}: {str(e)}")
                    continue

    results['native_language'] = language_results

    return results

def chi_square_analysis(df):
    """Perform chi-square tests for gender, age, discipline, and native language."""
    results = {}
    categories = ['determiner', 'preposition', 'negation', 'adverbial/other', 'total_stopwords']

    # Gender comparisons
    gender_results = {}
    if 'gender' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['gender'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    gender_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                gender_results[category] = {'error': str(e)}

    results['gender'] = gender_results

    # Age group comparisons
    age_results = {}
    if 'age' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['age'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    age_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                age_results[category] = {'error': str(e)}

    results['age'] = age_results

    # Discipline comparisons
    discipline_results = {}
    if 'discipline' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['discipline'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    discipline_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                discipline_results[category] = {'error': str(e)}

    results['discipline'] = discipline_results

    # Native language comparisons
    language_results = {}
    if 'native_language' in df.columns:
        for category in categories:
            count_col = f'{category}_count'
            if count_col not in df.columns:
                continue

            try:
                # Create bins based on quartiles
                bins = pd.qcut(df[count_col], 4, duplicates='drop').astype(str)
                contingency_table = pd.crosstab(df['native_language'], bins)

                if contingency_table.size > 0 and not (contingency_table == 0).all().all():
                    # Perform chi-square test
                    chi2, p, dof, expected = chi2_contingency(contingency_table)
                    language_results[category] = {
                        'chi2': float(chi2),
                        'p_value': float(p),
                        'dof': int(dof),
                        'contingency_table': contingency_table.to_dict()
                    }
            except Exception as e:
                language_results[category] = {'error': str(e)}

    results['native_language'] = language_results

    return results

def analyze_zipf_law(df):
    """Analyze Zipf's Law for stop words across different groups."""
    english_stopwords = set(stopwords.words('english'))
    results = {}

    # Overall analysis
    all_stop_words = []
    for _, row in df.iterrows():
        utterance = str(row.get('utterance', ''))
        tokens = re.findall(r'\b\w+\b', utterance.lower())
        all_stop_words.extend([token for token in tokens if token in english_stopwords])

    if all_stop_words:
        results['overall'] = calculate_zipf(all_stop_words)

    # By gender
    gender_results = {}
    if 'gender' in df.columns:
        for gender in df['gender'].unique():
            gender_utterances = df[df['gender'] == gender]['utterance']
            stop_words = []
            for utterance in gender_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                gender_results[gender] = calculate_zipf(stop_words)
    results['gender'] = gender_results

    # By age group
    age_results = {}
    if 'age' in df.columns:
        for age in df['age'].unique():
            age_utterances = df[df['age'] == age]['utterance']
            stop_words = []
            for utterance in age_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                age_results[age] = calculate_zipf(stop_words)
    results['age'] = age_results

    # By discipline
    discipline_results = {}
    if 'discipline' in df.columns:
        for discipline in df['discipline'].unique():
            disc_utterances = df[df['discipline'] == discipline]['utterance']
            stop_words = []
            for utterance in disc_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                discipline_results[discipline] = calculate_zipf(stop_words)
    results['discipline'] = discipline_results

    # By native language
    language_results = {}
    if 'native_language' in df.columns:
        for language in df['native_language'].unique():
            lang_utterances = df[df['native_language'] == language]['utterance']
            stop_words = []
            for utterance in lang_utterances:
                utterance = str(utterance)
                tokens = re.findall(r'\b\w+\b', utterance.lower())
                stop_words.extend([token for token in tokens if token in english_stopwords])
            if stop_words:
                language_results[language] = calculate_zipf(stop_words)
    results['native_language'] = language_results

    return results

def calculate_zipf(word_list):
    """Calculate Zipf's Law parameters for a list of words."""
    if not word_list:
        return {'error': 'Empty word list'}

    word_counts = Counter(word_list)
    word_freqs = [(word, count) for word, count in word_counts.items()]
    word_freqs.sort(key=lambda x: x[1], reverse=True)

    ranks = np.arange(1, len(word_freqs) + 1)
    frequencies = np.array([freq for _, freq in word_freqs])

    # Calculate the Zipf coefficient
    slope, intercept, r_value, p_value, std_err = linregress(
        np.log(ranks), np.log(frequencies))

    return {
        'zipf_coefficient': -float(slope),  # Negative as Zipf's law has a negative slope
        'r_squared': float(r_value**2),
        'p_value': float(p_value),
        'std_error': float(std_err),
        'intercept': float(intercept),
        'top_words': word_freqs[:10]  # Include top 10 words for inspection
    }

def save_results(results, filename):
    """Save results to a JSON file."""
    # Convert numpy types to Python native types
    def convert(o):
        if isinstance(o, np.integer):
            return int(o)
        elif isinstance(o, np.floating):
            return float(o)
        elif isinstance(o, np.ndarray):
            return o.tolist()
        else:
            return o

    with open(filename, 'w') as f:
        json.dump(results, f, default=convert, indent=2)

def main():
    # Step 1: Load the preprocessed CSV file
    csv_file_path = '/content/elfa_processed.csv'  # Update this path
    print(f"Loading CSV file from: {csv_file_path}")
    df = load_corpus(csv_file_path)

    if df.empty:
        print("Error: No data was loaded. Check your CSV file path.")
        return

    print(f"Loaded {len(df)} records with columns: {list(df.columns)}")

    # Step 2: Analyze stop words
    print("Analyzing stop words...")
    stopword_df = analyze_stopwords(df)

    if stopword_df.empty:
        print("Error: No stop word data was generated.")
        return

    print(f"Generated stopword analysis with {len(stopword_df)} records")

    # Step 3: Perform statistical analyses
    print("Running parametric tests...")
    parametric_results = parametric_tests(stopword_df)
    save_results(parametric_results, 'parametric_results.json')
    print("Saved parametric results to parametric_results.json")

    print("Running non-parametric tests...")
    nonparametric_results = nonparametric_tests(stopword_df)
    save_results(nonparametric_results, 'nonparametric_results.json')
    print("Saved non-parametric results to nonparametric_results.json")

    print("Running chi-square tests...")
    chi_square_results = chi_square_analysis(stopword_df)
    save_results(chi_square_results, 'chi_square_results.json')
    print("Saved chi-square results to chi_square_results.json")

    print("Running Zipf's Law analysis...")
    zipf_results = analyze_zipf_law(df)
    save_results(zipf_results, 'zipf_results.json')
    print("Saved Zipf's Law results to zipf_results.json")

    print("\nAll analyses completed successfully!")

if __name__ == '__main__':
    main()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Set style
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (12, 6)

# Mock data (replace with your actual data)
# Gender data
gender_data = {
    "Stopword Type": ["Determiners", "Prepositions", "Negations", "Adverbial/Other", "Total Stopwords"],
    "Male Mean": [0.088, 0.074, 0.014, 0.295, 0.472],
    "Female Mean": [0.072, 0.059, 0.016, 0.300, 0.447],
    "Chi-square": [248.38, 231.18, 0.0, 138.13, 191.31],
    "p-value": [1.16e-54, 6.32e-51, 1.0, 9.58e-30, 3.18e-41]
}
gender_df = pd.DataFrame(gender_data)

# Age data
age_data = {
    "Age Group": ["17-23", "24-30", "31-50", "51-over", "31-50>", "unknown"],
    "Determiners": [0.080, 0.078, 0.088, 0.072, 0.110, 0.093],
    "Prepositions": [0.064, 0.067, 0.071, 0.063, 0.092, 0.080],
    "Total Stopwords": [0.469, 0.460, 0.470, 0.435, 0.516, 0.494]
}
age_df = pd.DataFrame(age_data)

# Discipline data (top 5 highest and lowest)
discipline_data = {
    "Discipline": ["Social Policy", "Industrial Eng.", "Physics", "Slavonic Philology", "Other"],
    "Determiners": [0.123, 0.125, 0.001, 0.054, 0.046],
    "Total Stopwords": [0.123, 0.125, 0.000, 0.054, 0.046]
}
discipline_df = pd.DataFrame(discipline_data)

# Zipf's Law data (example word frequencies)
words = ["the", "of", "and", "to", "in", "a", "is", "that", "for", "it"]
frequencies = [5000, 3000, 2500, 2000, 1800, 1500, 1200, 1000, 800, 700]
zipf_df = pd.DataFrame({"Word": words, "Frequency": frequencies})

# Chi-square plot
plt.figure(figsize=(10, 6))
sns.barplot(x="Stopword Type", y="Chi-square", data=gender_df, palette="viridis")
plt.axhline(y=3.84, color='red', linestyle='--', label="Significance Threshold (p=0.05)")
plt.title("Chi-Square Test Results Across Stopword Types")
plt.ylabel("Chi-Square Statistic")
plt.xticks(rotation=45)
plt.legend()
plt.show()

# Gender mean comparison
plt.figure(figsize=(10, 6))
gender_melted = gender_df.melt(id_vars="Stopword Type", value_vars=["Male Mean", "Female Mean"],
                              var_name="Gender", value_name="Mean Usage")
sns.barplot(x="Stopword Type", y="Mean Usage", hue="Gender", data=gender_melted, palette="coolwarm")
plt.title("Stopword Usage by Gender")
plt.ylabel("Mean Usage")
plt.xticks(rotation=45)
plt.show()

# Age comparison
plt.figure(figsize=(10, 6))
age_melted = age_df.melt(id_vars="Age Group", value_vars=["Determiners", "Prepositions", "Total Stopwords"],
                         var_name="Stopword Type", value_name="Mean Usage")
sns.lineplot(x="Age Group", y="Mean Usage", hue="Stopword Type", data=age_melted, marker="o")
plt.title("Stopword Usage by Age Group")
plt.ylabel("Mean Usage")
plt.show()

# Discipline comparison
plt.figure(figsize=(10, 6))
discipline_melted = discipline_df.melt(id_vars="Discipline", value_vars=["Determiners", "Total Stopwords"],
                                      var_name="Stopword Type", value_name="Mean Usage")
sns.barplot(x="Discipline", y="Mean Usage", hue="Stopword Type", data=discipline_melted, palette="mako")
plt.title("Stopword Usage by Discipline")
plt.ylabel("Mean Usage")
plt.xticks(rotation=45)
plt.show()

# Zipf's Law plot
plt.figure(figsize=(10, 6))
zipf_df["Rank"] = range(1, len(zipf_df) + 1)
zipf_df["Log Rank"] = np.log10(zipf_df["Rank"])
zipf_df["Log Frequency"] = np.log10(zipf_df["Frequency"])

sns.regplot(x="Log Rank", y="Log Frequency", data=zipf_df, scatter_kws={"s": 100}, color="purple")
plt.title("Zipf's Law: Word Frequency Distribution (Log-Log Scale)")
plt.xlabel("Log(Rank)")
plt.ylabel("Log(Frequency)")
plt.show()

